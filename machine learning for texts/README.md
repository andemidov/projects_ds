# Проект для «Викишоп»

## Основные навыки: Python, Pandas, BERT, nltk, tf-idf

**Описание целей и задачи проекта**

Заказчик, интернет-магазин «Викишоп», запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. 

Необходимо обучить модель классифицировать комментарии на позитивные и негативные.

**Описание данных**

Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак. Набор данных содержит разметку о токсичности правок.


**План работы**

1. Загрузить и подготовьте данные.
2. Обучить разные модели. 
 - Метрика качества *F1* должна быть не меньше 0.75. 
3. Сделайть выводы.

Разработка такой модели позволит компании сократить издержки на штат сотрудников ответственных за корректность комментариев, тк за месяц может быть огромное количество комментариев и их правок, модель позволит рассматривать только отдельные из них, а не все. Этим компания сэкономит бюджет или сможет высвободить рабочие ресурсы на решение других задач.

## Выводы

Текст был лемматизирован и векторизирован при помощи TF-IDF.

Обучены следующие модели

LogisticRegression - лучшие параметры модели {'C': 10, 'penalty': 'l2'}, F1 = 0.76

LGBMRegressor - лучшие параметры модели {'learning_rate': 0.1, 'max_depth': 10, 'num_leaves': 10}, F1 = 0.68

KNeighborsClassifier лучшие параметры модели {'n_neighbors': 3, 'p': 1}, F1 = 0.19

CatBoostClassifier - лучшие параметры модели {'l2_leaf_reg': 1, 'learning_rate': 0.1, 'max_depth': 6}, F1 0.74

Лучше всех показала себя модель LogisticRegression - для обучения требуется 0.6 минут, F1 на тестовой выборке = 0.78

Модель прошла проверку на адекватность.
